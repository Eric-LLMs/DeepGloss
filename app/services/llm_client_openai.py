from openai import OpenAI
import os
import json
import config  # å¯¼å…¥ config

class LLMClient:
    def __init__(self):
        api_key = os.getenv("DEEP_SEEK_API_KEY")
        # ğŸ‘‡ å…³é”®ä¿®æ”¹ï¼šä¼ å…¥ base_url
        if api_key:
            self.client = OpenAI(
                api_key=api_key,
                base_url=config.OPENAI_BASE_URL  # ä½¿ç”¨è½¬å‘åœ°å€
            )
        else:
            self.client = None

    def explain_term_in_context(self, term, sentence):
        """
        è§£é‡Šå•è¯åœ¨ç‰¹å®šå¥å­ä¸­çš„å«ä¹‰ï¼Œå¹¶ç¿»è¯‘å¥å­ã€‚
        """
        if not self.client:
            return None

        prompt = f"""
        Context: "{sentence}"
        Term: "{term}"

        Task:
        1. Translate the sentence into Chinese.
        2. Explain the meaning of the term "{term}" specifically as it is used in this context (in Chinese).

        Return strictly JSON format:
        {{
            "translation": "ä¸­æ–‡ç¿»è¯‘...",
            "explanation": "å•è¯è§£é‡Š..."
        }}
        """

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            print(f"LLM Error: {e}")
            return None